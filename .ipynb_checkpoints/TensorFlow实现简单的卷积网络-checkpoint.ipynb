{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 两个卷基层 一个全连接层\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "sess = tf.InteractiveSession()  # 创建默认的InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    # 给权重制造一些随机的噪声来打破完全对称\n",
    "    # 截断的正态分布噪声，标准差设为0.1\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    # tf.coonstant常量矩阵，此处设置较小的正值0.1，避免死亡节点\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 二维卷积函数 x：输入  W：卷积的参数，比如[5,5,1,32]：前两个数字代表卷积核的尺寸，第三个数字代表有多少个channel，最后一个数字代表卷积核的数量\n",
    "def conv2d(x, W):\n",
    "    # strides代表卷积模板移动的步长，都是1代表不遗漏地划过图片的每一个点\n",
    "    # padding带白哦边界的处理方式，这里的SAME带白哦给边界加上padding让卷积的输出和输入保持同样的尺寸\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # max_pool最大池化函数\n",
    "    # 最大池化会保留原始像素块中灰度值最高的那一个像素，即保留最显著的特征\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])  # 特征（输入）\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])  # 真实的label\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])  # 1D的输入向量转为2D的图片结构：从1x784转为28x28，-1代表样本数量不固定，1代表颜色通道数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一个卷积层\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "# 使用conv2d函数进行卷积操作，并加上偏置，接着再使用ReLU激活函数进行非线性处理\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) \n",
    "# 最后使用最大池化函数对卷积的输出结果进行池化操作\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第二个卷积层\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用Dropout层\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# softmax层\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)  #学习率1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义评测准确率的操作\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 10, training accuracy 0.3\n",
      "step 20, training accuracy 0.34\n",
      "step 30, training accuracy 0.52\n",
      "step 40, training accuracy 0.58\n",
      "step 50, training accuracy 0.7\n",
      "step 60, training accuracy 0.74\n",
      "step 70, training accuracy 0.82\n",
      "step 80, training accuracy 0.86\n",
      "step 90, training accuracy 0.78\n",
      "step 100, training accuracy 0.88\n",
      "step 110, training accuracy 0.78\n",
      "step 120, training accuracy 0.82\n",
      "step 130, training accuracy 0.86\n",
      "step 140, training accuracy 0.88\n",
      "step 150, training accuracy 0.84\n",
      "step 160, training accuracy 0.92\n",
      "step 170, training accuracy 0.84\n",
      "step 180, training accuracy 0.88\n",
      "step 190, training accuracy 0.88\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "tf.global_variables_initializer().run() # 初始化所有参数\n",
    "for i in range(200):  # 20000次训练迭代\n",
    "    batch = mnist.train.next_batch(50)  # batch_size=50\n",
    "    if i % 10 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_:batch[1], keep_prob: 1.0})  # 评测时keep_prob设为1\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5}) # 训练时keep_prob此处设为0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9044\n"
     ]
    }
   ],
   "source": [
    "# 训练完成后，对测试集做测试，得到整体的分类准确率\n",
    "print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
